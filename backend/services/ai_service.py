"""
AIæœåŠ¡ç»Ÿä¸€æ¥å£
Unified Interface for AI Services

å°è£…å¯¹ä¸åŒAIæ¨¡å‹æä¾›å•†çš„APIè°ƒç”¨ã€‚
"""
import logging
import os
import time
import uuid
from typing import List, Dict, Optional, Any

# ç§»é™¤å¯¹volcenginesdkarkçš„é¡¶å±‚å¯¼å…¥ï¼Œæ”¹ä¸ºåœ¨æ–¹æ³•å†…éƒ¨åŠ¨æ€å¯¼å…¥

logger = logging.getLogger(__name__)


class ConversationContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, max_messages: int = 20, max_tokens: int = 32768):
        self.conversation_id = str(uuid.uuid4())
        self.messages: List[Dict[str, str]] = []
        self.max_messages = max_messages
        #self.max_tokens = max_tokens
        self.created_at = time.time()
        self.last_updated = time.time()

    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡"""
        message = {
            "role": role,
            "content": content
        }
        self.messages.append(message)
        self.last_updated = time.time()

        # ä¿æŒæ¶ˆæ¯æ•°é‡åœ¨é™åˆ¶å†…
        if len(self.messages) > self.max_messages:
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„å¯¹è¯
            system_messages = [msg for msg in self.messages if msg["role"] == "system"]
            recent_messages = self.messages[-(self.max_messages - len(system_messages)):]
            self.messages = system_messages + recent_messages

    def get_messages(self) -> List[Dict[str, str]]:
        """è·å–æ‰€æœ‰æ¶ˆæ¯"""
        return self.messages.copy()

    def clear_context(self):
        """æ¸…ç©ºä¸Šä¸‹æ–‡ï¼ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼‰"""
        system_messages = [msg for msg in self.messages if msg["role"] == "system"]
        self.messages = system_messages
        self.last_updated = time.time()

    def get_context_info(self) -> Dict[str, Any]:
        """è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        return {
            "conversation_id": self.conversation_id,
            "message_count": len(self.messages),
            "created_at": self.created_at,
            "last_updated": self.last_updated,
            "max_messages": self.max_messages,
            "max_tokens": self.max_tokens
        }


class ContextManager:
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç®¡ç†å¤šä¸ªå¯¹è¯ä¼šè¯"""

    def __init__(self):
        self.contexts: Dict[str, ConversationContext] = {}
        self.default_context_id = None

    def create_context(self, max_messages: int = 20, max_tokens: int = 32768) -> str:
        """åˆ›å»ºæ–°çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
        context = ConversationContext(max_messages, max_tokens)
        self.contexts[context.conversation_id] = context

        if self.default_context_id is None:
            self.default_context_id = context.conversation_id

        return context.conversation_id

    def get_context(self, context_id: Optional[str] = None) -> Optional[ConversationContext]:
        """è·å–å¯¹è¯ä¸Šä¸‹æ–‡"""
        if context_id is None:
            context_id = self.default_context_id

        return self.contexts.get(context_id) if context_id else None

    def delete_context(self, context_id: str):
        """åˆ é™¤å¯¹è¯ä¸Šä¸‹æ–‡"""
        if context_id in self.contexts:
            del self.contexts[context_id]

            if self.default_context_id == context_id:
                self.default_context_id = next(iter(self.contexts.keys()), None)

    def list_contexts(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰ä¸Šä¸‹æ–‡"""
        return [context.get_context_info() for context in self.contexts.values()]


# å…¨å±€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
context_manager = ContextManager()

class VolcengineService:
    """
    å°è£…ç«å±±å¼•æ“æ–¹èˆŸSDKçš„AIæ¨¡å‹è°ƒç”¨ã€‚
    SDKä¼šè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡ ARK_API_KEY è¯»å–å¯†é’¥ã€‚
    """
    def __init__(self):
        try:
            # ä¼˜å…ˆä½¿ç”¨.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥
            api_key = self._get_api_key_from_env()
            if not api_key:
                logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ARK_API_KEY")
                self.client = None
                return

            # åŠ¨æ€å¯¼å…¥ï¼Œé¿å…åœ¨æœªå®‰è£…ä¾èµ–æ—¶æ¨¡å—å¯¼å…¥å¤±è´¥
            from volcenginesdkarkruntime import Ark  # type: ignore
            self.client = Ark(
                base_url="https://ark.cn-beijing.volces.com/api/v3",
                api_key=api_key
            )
            logger.info("ç«å±±å¼•æ“æ–¹èˆŸSDKå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸã€‚")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–ç«å±±å¼•æ“æ–¹èˆŸSDKå®¢æˆ·ç«¯å¤±è´¥: {e}")
            logger.warning("è¯·ç¡®ä¿å·²æ­£ç¡®è®¾ç½® ARK_API_KEY ç¯å¢ƒå˜é‡ã€‚")
            self.client = None

    def _get_api_key_from_env(self):
        """ä».envæ–‡ä»¶è·å–APIå¯†é’¥"""
        try:
            from pathlib import Path
            env_path = Path(__file__).parent.parent.parent / ".env"
            if env_path.exists():
                with open(env_path, 'r') as f:
                    for line in f:
                        if line.startswith('ARK_API_KEY='):
                            return line.split('=', 1)[1].strip().strip('"\'')
        except Exception as e:
            logger.warning(f"è¯»å–.envæ–‡ä»¶å¤±è´¥: {e}")

        # å¦‚æœ.envæ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
        return os.environ.get("ARK_API_KEY")

    def is_available(self) -> bool:
        """æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.client is not None

    def chat_completion(
        self,
        model: str,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        response_format: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        è°ƒç”¨èŠå¤©è¡¥å…¨æ¨¡å‹ (å¦‚ doubao-lite, doubao-flash)ã€‚

        Args:
            model: æ¨¡å‹åç§°
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            response_format: å“åº”æ ¼å¼é…ç½®ï¼Œæ”¯æŒJSON Schema
        """
        if not self.is_available():
            logger.error("ç«å±±å¼•æ“æœåŠ¡ä¸å¯ç”¨ã€‚")
            return None

        try:
            logger.info(f"å‘æ¨¡å‹ {model} å‘é€è¯·æ±‚...")

            # æ„å»ºè¯·æ±‚å‚æ•°
            completion_params = {
                "model": model,
                "messages": messages,
                "temperature": temperature,
            }

            # å¦‚æœæŒ‡å®šäº†å“åº”æ ¼å¼ï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
            if response_format:
                completion_params["response_format"] = response_format
                logger.info(f"ä½¿ç”¨å“åº”æ ¼å¼: {response_format.get('type', 'text')}")

            completion = self.client.chat.completions.create(**completion_params)
            response_content = completion.choices[0].message.content
            logger.info(f"æˆåŠŸæ¥æ”¶åˆ°æ¨¡å‹ {model} çš„å“åº”ã€‚")
            logger.info(response_content)
            return response_content
        except Exception as e:
            logger.error(f"è°ƒç”¨æ¨¡å‹ {model} å¤±è´¥: {e}")
            return None

    def text_to_image(
        self,
        model: str,
        prompt: str,
        size: str = "2048x2048",
        sequential_generation: str = "auto",
        max_images: int = 1,
        stream: bool = False
    ) -> Optional[any]:
        """
        è°ƒç”¨æ–‡ç”Ÿå›¾æ¨¡å‹ (å¦‚ doubao-seedream-4-0-250828)ã€‚

        Args:
            model: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            size: å›¾åƒå°ºå¯¸ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
                  1. é¢„è®¾å€¼ï¼š1Kã€2Kã€4K
                  2. åƒç´ å€¼ï¼šå¦‚"2048x2048"ï¼Œé»˜è®¤"2048x2048"
                  æ€»åƒç´ èŒƒå›´ï¼š[1280x720, 4096x4096]ï¼Œå®½é«˜æ¯”èŒƒå›´ï¼š[1/16, 16]
            sequential_generation: ç»„å›¾è®¾ç½®ï¼Œ"auto" æˆ– "disabled"
            max_images: æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡ (1-5)
            stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º

        Returns:
            æ ¹æ®æ¨¡å¼è¿”å›ä¸åŒç»“æœï¼š
            - éæµå¼å•å›¾ï¼šè¿”å›å•ä¸ªURLå­—ç¬¦ä¸²
            - éæµå¼ç»„å›¾ï¼šè¿”å›URLåˆ—è¡¨
            - æµå¼æ¨¡å¼ï¼šè¿”å›ç”Ÿæˆå™¨å¯¹è±¡
        """
        if not self.is_available():
            logger.error("ç«å±±å¼•æ“æœåŠ¡ä¸å¯ç”¨ã€‚")
            return None
        try:
            logger.info(f"å‘æ–‡ç”Ÿå›¾æ¨¡å‹ {model} å‘é€è¯·æ±‚... (ç»„å›¾: {sequential_generation}, æµå¼: {stream}, æœ€å¤§å›¾ç‰‡: {max_images})")

            # æ”¯æŒå®˜æ–¹æ¨èçš„Kæ ¼å¼å’Œåƒç´ å°ºå¯¸
            def parse_size_with_k_format(size_str: str) -> str:
                """æ”¯æŒ1K/2Kæ ¼å¼å’Œåƒç´ å°ºå¯¸"""
                size_str = size_str.lower()

                # å®˜æ–¹æ¨èçš„Kæ ¼å¼ï¼ˆç§»é™¤è¶…é™çš„4Kï¼‰
                k_format_mapping = {
                    "1k": "1024x1024",
                    "2k": "2048x2048"
                }

                if size_str in k_format_mapping:
                    return k_format_mapping[size_str]

                # æ”¯æŒçš„åƒç´ æ ¼å¼
                if "x" in size_str:
                    try:
                        width, height = map(int, size_str.split("x"))
                        # éªŒè¯åƒç´ é™åˆ¶ (å®˜æ–¹ï¼šæ€»åƒç´ ä¸è¶…è¿‡6000Ã—6000)
                        if 512 <= width <= 2048 and 512 <= height <= 2048:
                            # éªŒè¯å®½é«˜æ¯”é™åˆ¶ [1/16, 16]
                            ratio = width / height
                            if 1/16 <= ratio <= 16:
                                return size_str
                    except:
                        pass

                # é»˜è®¤æ¨è2Kæ ¼å¼
                return "2k"

            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„sizeå‚æ•°
            size = parse_size_with_k_format(size)

            # éªŒè¯å¹¶é™åˆ¶max_images
            max_images = max(1, min(5, max_images))  # ç¡®ä¿1-5ä¹‹é—´

            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": model,
                "prompt": prompt,
                "size": size,
                "response_format": "url",
                "watermark": False
            }

            # ä»…å¯¹doubao-seedream-4-0-250828æ¨¡å‹æ·»åŠ ç»„å›¾å’Œæµå¼å‚æ•°
            if "seedream-4-0-250828" in model.lower():
                # ä¿®å¤ï¼šæ­£ç¡®è®¾ç½®ç»„å›¾å‚æ•°
                request_params["sequential_image_generation"] = sequential_generation
                request_params["stream"] = stream

                # å½“å¯ç”¨ç»„å›¾æ—¶ï¼Œéœ€è¦æ˜ç¡®è®¾ç½®max_imageså‚æ•°æ¥æ§åˆ¶ç”Ÿæˆæ•°é‡
                if sequential_generation == "auto" and max_images > 1:
                    try:
                        # ä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥è·¯å¾„
                        from volcenginesdkarkruntime.types.images import SequentialImageGenerationOptions
                        request_params["sequential_image_generation_options"] = SequentialImageGenerationOptions(
                            max_images=max_images
                        )
                        logger.info(f"è®¾ç½®ç»„å›¾é€‰é¡¹: max_images={max_images}")
                    except ImportError:
                        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å‚æ•°è®¾ç½®
                        request_params["max_images"] = max_images
                        logger.warning(f"SequentialImageGenerationOptions å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€å•å‚æ•°: max_images={max_images}")
                elif max_images > 1:
                    # å¦‚æœæ²¡æœ‰å¯ç”¨ç»„å›¾ä½†éœ€è¦å¤šå¼ å›¾ç‰‡ï¼Œå°è¯•ä½¿ç”¨max_imageså‚æ•°
                    request_params["max_images"] = max_images
                    logger.info(f"è®¾ç½®å¤šå›¾å‚æ•°: max_images={max_images}")

                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                logger.info(f"ç»„å›¾è¯·æ±‚å‚æ•°: sequential_image_generation={sequential_generation}, max_images={max_images}")

            # æµå¼æˆ–éæµå¼è°ƒç”¨
            if stream and "seedream-4-0-250828" in model.lower():
                # æµå¼è¾“å‡º - éœ€è¦å¤„ç†æµå¼å“åº”
                resp = self.client.images.generate(**request_params)

                # æµå¼å“åº”éœ€è¦è¿­ä»£è·å–å†…å®¹
                try:
                    # å¦‚æœrespæ˜¯ç”Ÿæˆå™¨ï¼Œéœ€è¦è¿­ä»£è·å–æœ€ç»ˆç»“æœ
                    if hasattr(resp, '__iter__') and not hasattr(resp, 'data'):
                        final_result = None

                        for chunk in resp:
                            # æ£€æŸ¥chunkæ˜¯å¦æœ‰å›¾åƒURL
                            if hasattr(chunk, 'url') and chunk.url:
                                final_result = chunk
                                break
                            elif hasattr(chunk, 'data') and chunk.data and len(chunk.data) > 0:
                                final_result = chunk
                                break

                        if final_result:
                            if hasattr(final_result, 'url') and final_result.url:
                                image_url = final_result.url
                                logger.info(f"æˆåŠŸä»æµå¼å“åº”è·å–å›¾åƒ")
                                return {"image_url": image_url, "local_path": None}
                            elif hasattr(final_result, 'data') and len(final_result.data) > 0:
                                image_url = final_result.data[0].url
                                logger.info(f"æˆåŠŸä»æµå¼å“åº”è·å–å›¾åƒ")
                                return {"image_url": image_url, "local_path": None}
                            else:
                                logger.error(f"æµå¼å“åº”æœªæ‰¾åˆ°æœ‰æ•ˆå›¾åƒæ•°æ®")
                                return None
                        else:
                            logger.error(f"æµå¼å“åº”è¿­ä»£å®Œæˆä½†æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
                            return None
                    else:
                        # ç›´æ¥å¤„ç†å“åº”å¯¹è±¡
                        if hasattr(resp, 'data') and len(resp.data) > 0:
                            image_url = resp.data[0].url
                            logger.info(f"æˆåŠŸæ¥æ”¶åˆ°æ–‡ç”Ÿå›¾æ¨¡å‹ {model} çš„æµå¼å“åº”ã€‚")
                            return {"image_url": image_url, "local_path": None}
                        else:
                            logger.error(f"æµå¼è¯·æ±‚å¤±è´¥ï¼Œå“åº”æ•°æ®ä¸ºç©º")
                            return None
                except Exception as e:
                    logger.error(f"å¤„ç†æµå¼å“åº”æ—¶å‡ºé”™: {e}")
                    return None
            else:
                # éæµå¼è¾“å‡º
                resp = self.client.images.generate(**request_params)

                # æ·»åŠ å“åº”è°ƒè¯•ä¿¡æ¯
                logger.info(f"APIå“åº”ç±»å‹: {type(resp)}")
                if hasattr(resp, 'data'):
                    logger.info(f"å“åº”æ•°æ®é•¿åº¦: {len(resp.data)}")
                    if hasattr(resp, 'usage') and hasattr(resp.usage, 'generated_images'):
                        logger.info(f"APIæŠ¥å‘Šç”Ÿæˆçš„å›¾ç‰‡æ•°: {resp.usage.generated_images}")

                # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†ç»„å›¾å“åº”
                if sequential_generation == "auto" and "seedream-4-0-250828" in model.lower():
                    # ç»„å›¾æ¨¡å¼ï¼Œè¿”å›å¤šä¸ªURL
                    if hasattr(resp, 'data') and len(resp.data) > 1:
                        # å¤šå›¾å“åº” - è¿”å›ç¬¬ä¸€ä¸ªå›¾ç‰‡
                        image_url = resp.data[0].url
                        logger.info(f"æˆåŠŸæ¥æ”¶åˆ°æ–‡ç”Ÿå›¾æ¨¡å‹ {model} çš„ç»„å›¾å“åº”ï¼Œå…± {len(resp.data)} å¼ å›¾ç‰‡ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ ã€‚")
                        return {"image_url": image_url, "local_path": None}
                    else:
                        # APIå¯èƒ½è¿”å›å•å›¾ï¼Œå°è¯•è·å–å•å›¾URL
                        if hasattr(resp, 'data') and len(resp.data) > 0:
                            image_url = resp.data[0].url
                            logger.warning(f"ç»„å›¾è¯·æ±‚ä½†è¿”å›å•å›¾ï¼Œæ¨¡å‹: {model}ï¼Œå“åº”æ•°æ®é•¿åº¦: {len(resp.data)}")
                            return {"image_url": image_url, "local_path": None}
                        else:
                            logger.error(f"ç»„å›¾è¯·æ±‚å¤±è´¥ï¼Œå“åº”æ•°æ®ä¸ºç©º")
                            return None
                else:
                    # å•å›¾æ¨¡å¼
                    if hasattr(resp, 'data') and len(resp.data) > 0:
                        image_url = resp.data[0].url
                        logger.info(f"æˆåŠŸæ¥æ”¶åˆ°æ–‡ç”Ÿå›¾æ¨¡å‹ {model} çš„å•å›¾å“åº”ã€‚")
                        return {"image_url": image_url, "local_path": None}
                    else:
                        logger.error(f"å•å›¾è¯·æ±‚å¤±è´¥ï¼Œå“åº”æ•°æ®ä¸ºç©º")
                        return None

        except Exception as e:
            logger.error(f"è°ƒç”¨æ–‡ç”Ÿå›¾æ¨¡å‹ {model} å¤±è´¥: {e}")
            return None

    def image_to_image(self, model: str, prompt: str, image_url: str, image_base64: Optional[str] = None, size: str = "1024x1024", strength: float = 0.8) -> Optional[str]:
        """
        è°ƒç”¨å›¾ç”Ÿå›¾æ¨¡å‹ (doubao-seedream-4-0-250828)ã€‚

        Args:
            model: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            image_url: å‚è€ƒå›¾ç‰‡URL
            image_base64: å‚è€ƒå›¾ç‰‡çš„Base64ç¼–ç  (å¯é€‰)
            size: å›¾ç‰‡å°ºå¯¸ (å¦‚ "1024x1024", "768x1024" ç­‰)
            strength: ç”Ÿæˆå¼ºåº¦/æ¸©åº¦ (0.0-1.0)ï¼Œæ§åˆ¶ä¸å‚è€ƒå›¾çš„ç›¸ä¼¼åº¦
        """
        if not self.is_available():
            logger.error("ç«å±±å¼•æ“æœåŠ¡ä¸å¯ç”¨ã€‚")
            return None
        try:
            logger.info(f"å‘å›¾ç”Ÿå›¾æ¨¡å‹ {model} å‘é€è¯·æ±‚...")
            logger.info(f"å‚æ•°: size={size}, strength={strength}")

            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": model,
                "prompt": prompt,
                "size": size,  # ä½¿ç”¨ä¼ å…¥çš„å°ºå¯¸å‚æ•°
                "response_format": "url",
                "watermark": False
            }

            # æ³¨æ„ï¼šè±†åŒ…çš„å›¾åƒç”ŸæˆAPIä¸æ”¯æŒtemperatureå‚æ•°
            # strengthå‚æ•°ä»…ç”¨äºå‰ç«¯æ§åˆ¶ï¼Œè¿™é‡Œè®°å½•æ—¥å¿—ä½†ä¸ä¼ é€’ç»™API
            logger.info(f"ç”Ÿæˆå¼ºåº¦å‚æ•°: {strength} (ä¸ä¼ é€’ç»™API)")

            # ä¼˜å…ˆä½¿ç”¨image_base64ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨image_url
            if image_base64:
                # ç¡®ä¿Base64æ ¼å¼æ­£ç¡®
                if not image_base64.startswith("data:image/"):
                    image_base64 = f"data:image/png;base64,{image_base64}"
                request_params["image"] = image_base64
                logger.info(f"ä½¿ç”¨Base64å›¾ç‰‡è¾“å…¥")
            elif image_url:
                request_params["image"] = image_url
                logger.info(f"ä½¿ç”¨URLå›¾ç‰‡è¾“å…¥: {image_url}")
            else:
                # å¦‚æœéƒ½æ²¡æœ‰ï¼Œåˆ™çº¯æ–‡æœ¬ç”Ÿå›¾
                logger.info(f"æœªæä¾›å‚è€ƒå›¾ç‰‡ï¼Œè¿›è¡Œçº¯æ–‡æœ¬ç”Ÿå›¾")

            resp = self.client.images.generate(**request_params)
            edited_image_url = resp.data[0].url
            logger.info(f"æˆåŠŸæ¥æ”¶åˆ°å›¾ç”Ÿå›¾æ¨¡å‹ {model} çš„å“åº”ã€‚")
            return edited_image_url
        except Exception as e:
            logger.error(f"è°ƒç”¨å›¾ç”Ÿå›¾æ¨¡å‹ {model} å¤±è´¥: {e}")
            return None

    def multi_reference_text_to_image(
        self,
        model: str,
        prompt: str,
        reference_images: list,
        max_images: int = 1
    ):
        """
        ä½¿ç”¨å¤šå‚è€ƒå›¾ç”Ÿæˆå›¾ç‰‡ï¼ˆdoubao-seedream-4.0ï¼‰

        Args:
            model: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            reference_images: å‚è€ƒå›¾ç‰‡è·¯å¾„åˆ—è¡¨
            max_images: æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡

        Returns:
            ç”Ÿæˆçš„å›¾ç‰‡URL
        """
        if not self.is_available():
            logger.error("ç«å±±å¼•æ“æœåŠ¡ä¸å¯ç”¨ã€‚")
            return None

        try:
            import base64

            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": model,
                "prompt": prompt,
                "size": "1024x1024",
                "response_format": "url",
                "watermark": False
            }

            # ä½¿ç”¨image_to_image APIæ¥æ”¯æŒå‚è€ƒå›¾ç‰‡
            if len(reference_images) > 0:
                logger.info(f"ä½¿ç”¨å›¾ç”Ÿå›¾APIæ¥æ”¯æŒ{len(reference_images)}å¼ å‚è€ƒå›¾ç‰‡")

                # è·å–ç¬¬ä¸€å¼ å‚è€ƒå›¾ç‰‡
                ref_path = reference_images[0]
                try:
                    with open(ref_path, 'rb') as f:
                        image_data = f.read()
                    # ä½¿ç”¨image_to_image API
                    result = self.image_to_image(
                        model=model,
                        prompt=prompt,
                        image_url=None,  # ä¸ä½¿ç”¨URL
                        image_base64=base64.b64encode(image_data).decode('utf-8')
                    )
                    logger.info(f"æˆåŠŸè°ƒç”¨å›¾ç”Ÿå›¾APIå¤„ç†å‚è€ƒå›¾ç‰‡")
                    return result
                except Exception as e:
                    logger.error(f"å›¾ç”Ÿå›¾APIè°ƒç”¨å¤±è´¥: {e}")
                    # é™çº§åˆ°æ™®é€šæ–‡ç”Ÿå›¾ï¼Œä½†åœ¨promptä¸­æè¿°å‚è€ƒå›¾
                    logger.info("ğŸ”„ å›¾ç”Ÿå›¾APIå¤±è´¥ï¼Œé™çº§åˆ°å¢å¼ºç‰ˆæ–‡ç”Ÿå›¾æ¨¡å¼")

                    # ä½¿ç”¨æ™ºèƒ½çš„å‚è€ƒå›¾æè¿°å¢å¼ºprompt
                    enhanced_prompt = self._enhance_prompt_with_reference_description(prompt, ref_path)
                    logger.info(f"âœ… å·²åŸºäºå‚è€ƒå›¾å¢å¼ºpromptï¼Œæ–°å¢æè¿°é•¿åº¦: {len(enhanced_prompt) - len(prompt)} å­—ç¬¦")

                    # è°ƒç”¨å¢å¼ºçš„æ–‡ç”Ÿå›¾
                    result = self.text_to_image(
                        model=model,
                        prompt=enhanced_prompt,
                        size="1024x1024",
                        response_format="url",
                        watermark=False
                    )

                    if result:
                        logger.info(f"âœ… é™çº§æ¨¡å¼ç”ŸæˆæˆåŠŸï¼Œä½†ä»å»ºè®®æ£€æŸ¥å›¾ç‰‡ä¸€è‡´æ€§")
                    else:
                        logger.error(f"âŒ é™çº§æ¨¡å¼ä¹Ÿå¤±è´¥äº†")

                    return result
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def _enhance_prompt_with_reference_description(self, original_prompt: str, reference_image_path: str) -> str:
        """
        åŸºäºå‚è€ƒå›¾ç‰‡æ™ºèƒ½å¢å¼ºpromptï¼Œç¡®ä¿é£æ ¼ä¸€è‡´æ€§
        å½“å›¾ç”Ÿå›¾APIå¤±è´¥æ—¶ï¼Œé€šè¿‡æ–‡å­—æè¿°å°½é‡ä¿æŒä¸€è‡´æ€§
        """
        try:
            import base64

            # è¯»å–å‚è€ƒå›¾ç‰‡
            with open(reference_image_path, 'rb') as f:
                image_data = f.read()

            # ä½¿ç”¨visionæ¨¡å‹åˆ†æå‚è€ƒå›¾ç‰‡
            vision_prompt = """
            è¯·åˆ†æè¿™å¼ æ¼«ç”»å›¾ç‰‡çš„å†…å®¹ï¼Œé‡ç‚¹å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼Œç”¨äºä¿æŒæ¼«ç”»é£æ ¼ä¸€è‡´æ€§ï¼š

            1. **è§’è‰²å¤–è§‚ç‰¹å¾**ï¼šå‘å‹ã€å‘è‰²ã€é¢éƒ¨ç‰¹å¾ã€æœè£…æ¬¾å¼å’Œé¢œè‰²
            2. **ç»˜ç”»é£æ ¼ç‰¹å¾**ï¼šçº¿æ¡é£æ ¼ã€è‰²å½©é£æ ¼ã€æ¸²æŸ“æ–¹å¼ã€æ•´ä½“è‰ºæœ¯é£æ ¼
            3. **åœºæ™¯ç‰¹å¾**ï¼šèƒŒæ™¯å¤æ‚åº¦ã€æ„å›¾æ–¹å¼ã€å…‰å½±æ•ˆæœã€æ°›å›´æƒ…ç»ª

            è¯·ç”¨ç®€æ´ä½†è¯¦ç»†çš„æ–¹å¼æè¿°è¿™äº›å…³é”®ç‰¹å¾ï¼Œå°†ç”¨äºæŒ‡å¯¼ä¸‹ä¸€å¼ å›¾ç‰‡çš„ç”Ÿæˆï¼Œç¡®ä¿é£æ ¼å®Œå…¨ä¸€è‡´ã€‚
            """

            # è°ƒç”¨vision APIåˆ†æå›¾ç‰‡ï¼ˆå¦‚æœæœ‰ç›¸å…³åŠŸèƒ½ï¼‰
            try:
                vision_result = self.vision_analyze_image(
                    image_base64=base64.b64encode(image_data).decode('utf-8'),
                    prompt=vision_prompt
                )

                if vision_result:
                    # åŸºäºåˆ†æç»“æœå¢å¼ºprompt
                    consistency_prompt = f"""
                    **é‡è¦ï¼šé£æ ¼ä¸€è‡´æ€§è¦æ±‚**
                    åŸºäºå‚è€ƒå›¾ç‰‡åˆ†æï¼š{vision_result}

                    **å¼ºåˆ¶è¦æ±‚**ï¼š
                    1. ä¸¥æ ¼ä¿æŒä¸å‚è€ƒå›¾ç‰‡ç›¸åŒçš„è§’è‰²å¤–è§‚å’Œæœè£…
                    2. ä¿æŒå®Œå…¨ç›¸åŒçš„ç»˜ç”»é£æ ¼å’Œçº¿æ¡å¤„ç†æ–¹å¼
                    3. ä¿æŒç›¸åŒçš„è‰²å½©é£æ ¼å’Œé…è‰²æ–¹æ¡ˆ
                    4. ä¿æŒç›¸ä¼¼çš„æ„å›¾å’Œè§†è§‰è¡¨ç°åŠ›

                    **åŸåœºæ™¯æè¿°**ï¼š{original_prompt}
                    """
                    logger.info(f"âœ… æˆåŠŸåˆ†æå‚è€ƒå›¾ç‰‡å¹¶ç”Ÿæˆä¸€è‡´æ€§prompt")
                    return consistency_prompt

            except Exception as vision_error:
                logger.warning(f"ğŸ”„ Visionåˆ†æå¤±è´¥ï¼Œä½¿ç”¨é€šç”¨ä¸€è‡´æ€§æè¿°: {vision_error}")

            # é™çº§åˆ°é€šç”¨ä¸€è‡´æ€§æè¿°
            consistency_enhancement = """
            **é‡è¦ï¼šé£æ ¼ä¸€è‡´æ€§è¦æ±‚**
            åŸºäºå‚è€ƒå›¾ç‰‡ï¼Œç¡®ä¿ä»¥ä¸‹ä¸€è‡´æ€§ï¼š
            1. ä¸¥æ ¼ä¿æŒç›¸åŒçš„è§’è‰²å¤–è§‚ã€å‘å‹ã€æœè£…å’Œé…é¥°
            2. ä¿æŒå®Œå…¨ç›¸åŒçš„æ¼«ç”»ç»˜ç”»é£æ ¼å’Œçº¿æ¡ç‰¹å¾
            3. ä¿æŒç›¸åŒçš„è‰²å½©å¤„ç†æ–¹å¼å’Œæ•´ä½“è‰²è°ƒ
            4. ä¿æŒç›¸ä¼¼çš„è§’è‰²æ¯”ä¾‹å’Œèº«æç‰¹å¾
            5. ä¿æŒç›¸åŒçš„èƒŒæ™¯æ¸²æŸ“é£æ ¼å’Œç»†èŠ‚å¤„ç†ç¨‹åº¦
            """

            enhanced_prompt = original_prompt + consistency_enhancement
            logger.info(f"âœ… ä½¿ç”¨é€šç”¨ä¸€è‡´æ€§æè¿°å¢å¼ºprompt")
            return enhanced_prompt

        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½promptå¢å¼ºå¤±è´¥: {e}")
            # æœ€åŸºç¡€çš„å¢å¼º
            return original_prompt + "ï¼Œä¿æŒä¸å‰ä¸€å¼ å›¾ç‰‡å®Œå…¨ç›¸åŒçš„è§’è‰²å¤–è§‚å’Œç»˜ç”»é£æ ¼"

    def _extract_feature(self, analysis: str, keywords: list) -> str:
        """ä»åˆ†æç»“æœä¸­æå–ç‰¹å®šå…³é”®è¯ç›¸å…³çš„æè¿°"""
        try:
            sentences = analysis.split('ã€‚')
            for sentence in sentences:
                for keyword in keywords:
                    if keyword in sentence:
                        return sentence.strip()
            return "ç‰¹å¾æè¿°æœªæ‰¾åˆ°"
        except:
            return "ç‰¹å¾æå–å¤±è´¥"

    def enhance_prompt_with_reference_description(self, original_prompt: str, reference_image_path: str) -> str:
        """
        åŸºäºå‚è€ƒå›¾ç‰‡æ™ºèƒ½å¢å¼ºpromptï¼Œç¡®ä¿é£æ ¼ä¸€è‡´æ€§
        å½“å›¾ç”Ÿå›¾APIå¤±è´¥æ—¶ï¼Œé€šè¿‡æ–‡å­—æè¿°å°½é‡ä¿æŒä¸€è‡´æ€§
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹åŸºäºå‚è€ƒå›¾ç‰‡å¢å¼ºprompt: {reference_image_path}")

            # é™çº§åˆ°é€šç”¨ä¸€è‡´æ€§æè¿°
            consistency_enhancement = """

**é‡è¦ï¼šé£æ ¼ä¸€è‡´æ€§è¦æ±‚**
åŸºäºå‚è€ƒå›¾ç‰‡ï¼Œç¡®ä¿ä»¥ä¸‹ä¸€è‡´æ€§ï¼š
1. ä¸¥æ ¼ä¿æŒç›¸åŒçš„è§’è‰²å¤–è§‚ã€å‘å‹ã€æœè£…å’Œé…é¥°
2. ä¿æŒå®Œå…¨ç›¸åŒçš„æ¼«ç”»ç»˜ç”»é£æ ¼å’Œçº¿æ¡ç‰¹å¾
3. ä¿æŒç›¸åŒçš„è‰²å½©å¤„ç†æ–¹å¼å’Œæ•´ä½“è‰²è°ƒ
4. ä¿æŒç›¸ä¼¼çš„è§’è‰²æ¯”ä¾‹å’Œèº«æç‰¹å¾
5. ä¿æŒç›¸åŒçš„èƒŒæ™¯æ¸²æŸ“é£æ ¼å’Œç»†èŠ‚å¤„ç†ç¨‹åº¦

**å¼ºåˆ¶è¦æ±‚** åŠ¡å¿…ç¡®ä¿è§’è‰²å¤–è§‚ã€æœè£…ã€å‘å‹ä¸å‚è€ƒå›¾ç‰‡å®Œå…¨ä¸€è‡´
**å¼ºåˆ¶è¦æ±‚** ä¿æŒå®Œå…¨ç›¸åŒçš„ç»˜ç”»é£æ ¼å’Œè‰²å½©å¤„ç†æ–¹å¼
"""

            enhanced_prompt = original_prompt + consistency_enhancement
            logger.info(f"âœ… ä½¿ç”¨é€šç”¨ä¸€è‡´æ€§æè¿°å¢å¼ºpromptï¼Œé•¿åº¦: {len(enhanced_prompt)} å­—ç¬¦")
            return enhanced_prompt

        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½promptå¢å¼ºå¤±è´¥: {e}")
            # æœ€åŸºç¡€çš„å¢å¼º
            return original_prompt + "ï¼Œä¿æŒä¸å‰ä¸€å¼ å›¾ç‰‡å®Œå…¨ç›¸åŒçš„è§’è‰²å¤–è§‚å’Œç»˜ç”»é£æ ¼"


# åˆ›å»ºå…¨å±€AIæœåŠ¡å®ä¾‹
volc_service = VolcengineService()

# ------------------ æ–°å¢å¯¹å¤–ç»Ÿä¸€åŒ…è£…ç±»ï¼ˆå¼‚æ­¥ï¼‰ ------------------
import time
from pathlib import Path

class AIService:
    """
    å¯¹å¤–æä¾›ç»Ÿä¸€çš„å¼‚æ­¥æ¥å£ï¼Œç¡®ä¿100% AIæœåŠ¡ï¼Œæ— é™çº§ã€‚
    """
    TEXT_MODELS = [
        "deepseek-v3-1-terminus",  # ä¸»è¦æ¨¡å‹
    ]
    IMAGE_MODELS = [
        "doubao-seedream-4-0-250828",
    ]

    def __init__(self, provider: Optional[VolcengineService] = None):
        self.provider = provider or volc_service
        self.context_manager = context_manager

    def is_available(self) -> bool:
        return self.provider.is_available()

    def _parse_size(self, size: str) -> tuple[int, int]:
        """
        è§£æå›¾åƒå°ºå¯¸å­—ç¬¦ä¸²ï¼Œè¿”å›å®½åº¦å’Œé«˜åº¦

        Args:
            size: å°ºå¯¸å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º "å®½xé«˜"ï¼Œå¦‚ "1024x1024"

        Returns:
            (width, height): å®½åº¦å’Œé«˜åº¦çš„å…ƒç»„
        """
        try:
            if 'x' in size:
                width, height = size.split('x')
                return int(width), int(height)
            else:
                # å¦‚æœæ ¼å¼ä¸æ­£ç¡®ï¼Œè¿”å›é»˜è®¤å°ºå¯¸
                logger.warning(f"æ— æ•ˆçš„å°ºå¯¸æ ¼å¼: {size}ï¼Œä½¿ç”¨é»˜è®¤å°ºå¯¸ 1024x1024")
                return 1024, 1024
        except (ValueError, AttributeError) as e:
            logger.error(f"è§£æå°ºå¯¸å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å°ºå¯¸ 1024x1024")
            return 1024, 1024

    def get_available_models(self) -> List[str]:
        return self.TEXT_MODELS + self.IMAGE_MODELS

    def create_json_schema_response_format(self, schema: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºJSON Schemaå“åº”æ ¼å¼"""
        return {
            "type": "json_schema",
            "json_schema": {
                "name": "response",
                "schema": schema,
                "strict": True
            }
        }

    
    def create_text_analysis_schema(self) -> Dict[str, Any]:
        """åˆ›å»ºæ–‡æœ¬åˆ†æJSON Schema"""
        return {
            "type": "object",
            "properties": {
                "summary": {
                    "type": "string",
                    "description": "æ–‡æœ¬æ‘˜è¦ï¼Œä¸è¶…è¿‡200å­—"
                },
                "key_points": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "å…³é”®ç‚¹åˆ—è¡¨"
                },
                "sentiment": {
                    "type": "string",
                    "enum": ["positive", "negative", "neutral"],
                    "description": "æƒ…æ„Ÿå€¾å‘"
                },
                "entities": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "type": {"type": "string"},
                            "description": {"type": "string"}
                        }
                    }
                }
            },
            "required": ["summary", "key_points", "sentiment"]
        }

    def create_simple_text_segmentation_schema(self) -> Dict[str, Any]:
        """åˆ›å»ºç®€åŒ–ç‰ˆæ–‡æœ¬åˆ†æ®µJSON Schema - å¼ºåˆ¶ä½¿ç”¨JSON Schema"""
        return {
            "type": "object",
            "properties": {
                "segments": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "content": {
                                "type": "string",
                                "description": "æ®µè½æ–‡æœ¬å†…å®¹"
                            },
                            "segment_type": {
                                "type": "string",
                                "description": "æ®µè½ç±»å‹",
                                "enum": ["dialogue", "action", "description", "transition", "climax", "resolution"]
                            },
                            "scene_setting": {
                                "type": "string",
                                "description": "åœºæ™¯è®¾ç½®"
                            },
                            "characters": {
                                "type": "string",
                                "description": "å‡ºç°çš„è§’è‰²ï¼Œç”¨é€—å·åˆ†éš”"
                            },
                            "emotional_tone": {
                                "type": "string",
                                "description": "æƒ…æ„ŸåŸºè°ƒ"
                            },
                            "visual_focus": {
                                "type": "string",
                                "description": "è§†è§‰ç„¦ç‚¹"
                            }
                        },
                        "required": ["content", "segment_type", "scene_setting", "characters", "emotional_tone", "visual_focus"]
                    }
                }
            },
            "required": ["segments"]
        }

    def create_character_analysis_schema(self) -> Dict[str, Any]:
        """åˆ›å»ºè§’è‰²åˆ†æJSON Schema"""
        return {
            "type": "object",
            "properties": {
                "characters": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "description": {"type": "string"},
                            "role": {"type": "string"},
                            "traits": {"type": "array", "items": {"type": "string"}}
                        },
                        "required": ["name", "description", "role"]
                    }
                },
                "relationships": {
                    "type": "object",
                    "description": "è§’è‰²å…³ç³»"
                },
                "character_count": {
                    "type": "integer",
                    "description": "è§’è‰²æ€»æ•°"
                }
            },
            "required": ["characters", "character_count"]
        }

    def create_script_generation_schema(self) -> Dict[str, Any]:
        """åˆ›å»ºè„šæœ¬ç”ŸæˆJSON Schema"""
        return {
            "type": "object",
            "properties": {
                "scenes": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "scene_number": {"type": "integer"},
                            "setting": {"type": "string"},
                            "characters": {"type": "array", "items": {"type": "string"}},
                            "dialogue": {"type": "string"},
                            "action": {"type": "string"},
                            "estimated_time": {"type": "string"}
                        },
                        "required": ["scene_number", "setting", "dialogue"]
                    }
                },
                "total_scenes": {
                    "type": "integer",
                    "description": "åœºæ™¯æ€»æ•°"
                },
                "estimated_duration": {
                    "type": "string",
                    "description": "é¢„ä¼°æ€»æ—¶é•¿"
                }
            },
            "required": ["scenes", "total_scenes"]
        }

    def create_text_segmentation_schema(self) -> Dict[str, Any]:
        """åˆ›å»ºæ–‡æœ¬åˆ†æ®µJSON Schema - æ¼«ç”»å¯¼å‘ç‰ˆæœ¬ï¼ˆå…¼å®¹è±†åŒ…APIï¼‰"""
        return {
            "type": "object",
            "properties": {
                "segments": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "content": {
                                "type": "string",
                                "description": "æ®µè½å®Œæ•´æ–‡æœ¬å†…å®¹"
                            },
                            "start_index": {
                                "type": "integer",
                                "description": "åœ¨åŸæ–‡ä¸­çš„èµ·å§‹ä½ç½®"
                            },
                            "end_index": {
                                "type": "integer",
                                "description": "åœ¨åŸæ–‡ä¸­çš„ç»“æŸä½ç½®"
                            },
                            "segment_type": {
                                "type": "string",
                                "enum": ["dialogue", "action", "description", "general"],
                                "description": "æ®µè½ç±»å‹"
                            },
                            "scene_setting": {
                                "type": "string",
                                "description": "å…·ä½“ç¯å¢ƒæè¿°ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€æ°›å›´ï¼‰"
                            },
                            "characters_present": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "å‡ºåœºè§’è‰²åˆ—è¡¨"
                            },
                            "emotional_tone": {
                                "type": "string",
                                "description": "æƒ…æ„ŸåŸºè°ƒ"
                            },
                            "key_events": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "å…³é”®äº‹ä»¶åˆ—è¡¨"
                            },
                            "transition_clues": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "è¿‡æ¸¡çº¿ç´¢"
                            },
                            "character_descriptions": {
                                "type": "object",
                                "description": "è§’è‰²å¤–è²Œæè¿°å…³é”®è¯",
                                "additionalProperties": {
                                    "type": "array",
                                    "items": {"type": "string"}
                                }
                            },
                            "scene_elements": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "ç¯å¢ƒè§†è§‰è¦ç´ "
                            },
                            "visual_keywords": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "æ•´ä½“è§†è§‰å…³é”®è¯"
                            },
                            "character_importance": {
                                "type": "object",
                                "description": "è§’è‰²é‡è¦æ€§æ ‡è¯†",
                                "additionalProperties": {
                                    "type": "boolean"
                                }
                            },
                            "comic_suitability": {
                                "type": "number",
                                "minimum": 0,
                                "maximum": 1,
                                "description": "æ¼«ç”»é€‚é…åº¦è¯„åˆ†(0-1)"
                            },
                            "panel_focus": {
                                "type": "string",
                                "description": "ç”»é¢ç„¦ç‚¹å»ºè®®"
                            }
                        },
                        "required": ["content", "characters_present", "character_descriptions", "scene_elements", "visual_keywords", "comic_suitability"]
                    }
                }
            },
            "required": ["segments"]
        }

    async def health_check(self) -> Dict[str, bool]:
        """
        è¿”å›å„æ¨¡å‹å¯ç”¨çŠ¶æ€çš„å­—å…¸ï¼Œç”¨äºè·¯ç”±å±‚å¥åº·æ£€æŸ¥ã€‚
        è‹¥åº•å±‚ä¸å¯ç”¨ï¼Œåˆ™å…¨éƒ¨ä¸º Falseã€‚
        """
        is_up = self.provider.is_available()
        models = self.get_available_models()
        status: Dict[str, bool] = {}
        for m in models:
            status[m] = bool(is_up)
        return status

    async def generate_text(
        self,
        prompt: str,
        model_preference: str = "deepseek-v3-1-terminus",
        max_tokens: int = 32768,
        temperature: float = 0.7,
        context_id: Optional[str] = None,
        use_json_schema: bool = False,
        schema_type: Optional[str] = None
    ) -> str:
        """
        ç”Ÿæˆæ–‡æœ¬ï¼ˆç”¨äºæç¤ºè¯å¢å¼ºã€åˆ†æç­‰ï¼‰ã€‚

        Args:
            prompt: æç¤ºè¯
            model_preference: æ¨¡å‹åå¥½
            max_tokens: æœ€å¤§tokenæ•°
            temperature: æ¸©åº¦å‚æ•°
            context_id: ä¸Šä¸‹æ–‡IDï¼Œç”¨äºå¤šè½®å¯¹è¯
            use_json_schema: æ˜¯å¦ä½¿ç”¨JSON Schema
            schema_type: Schemaç±»å‹ (text_analysis, character_analysis, script_generation)
        """
        # ç®€åŒ–æ¨¡å‹é€‰æ‹©ï¼šä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
        model = model_preference if model_preference in self.TEXT_MODELS else self.TEXT_MODELS[0]

        # è·å–ä¸Šä¸‹æ–‡
        context = self.context_manager.get_context(context_id)
        if not context:
            # å¦‚æœæ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
            context_id = self.context_manager.create_context()
            context = self.context_manager.get_context(context_id)

        # æ„å»ºæ¶ˆæ¯
        messages = context.get_messages() if context else []
        messages.append({"role": "user", "content": prompt})

        # æ„å»ºå“åº”æ ¼å¼
        response_format = None
        if use_json_schema and schema_type:
            if schema_type == "text_analysis":
                schema = self.create_text_analysis_schema()
            elif schema_type == "character_analysis":
                schema = self.create_character_analysis_schema()
            elif schema_type == "script_generation":
                schema = self.create_script_generation_schema()
            elif schema_type == "text_segmentation":
                schema = self.create_text_segmentation_schema()
            elif schema_type == "simple_text_segmentation":
                schema = self.create_simple_text_segmentation_schema()
            else:
                schema = None

            if schema:
                response_format = self.create_json_schema_response_format(schema)

        if self.provider.is_available():
            try:
                logger.info(f"ğŸ”„ ä½¿ç”¨æ¨¡å‹: {model}")
                result = self.provider.chat_completion(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    response_format=response_format
                )

                if isinstance(result, str) and result.strip():
                    logger.info(f"âœ… æ¨¡å‹ {model} è°ƒç”¨æˆåŠŸ")
                    # å°†å¯¹è¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                    if context:
                        context.add_message("user", prompt)
                        context.add_message("assistant", result.strip())

                    return result.strip()
                else:
                    raise RuntimeError(f"æ¨¡å‹ {model} è¿”å›ç©ºç»“æœ")
            except Exception as e:
                logger.error(f"âŒ æ¨¡å‹ {model} è°ƒç”¨å¤±è´¥: {e}")
                raise RuntimeError(f"AIæ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
        else:
            raise RuntimeError("AIæ–‡æœ¬æœåŠ¡ä¸å¯ç”¨")

    async def generate_text_with_context(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        model_preference: str = "deepseek-v3-1-terminus",
        temperature: float = 0.7,
        context_id: Optional[str] = None,
        clear_context: bool = False
    ) -> Dict[str, Any]:
        """
        å¸¦ä¸Šä¸‹æ–‡ç®¡ç†çš„æ–‡æœ¬ç”Ÿæˆ

        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            model_preference: æ¨¡å‹åå¥½
            temperature: æ¸©åº¦å‚æ•°
            context_id: ä¸Šä¸‹æ–‡ID
            clear_context: æ˜¯å¦æ¸…ç©ºä¸Šä¸‹æ–‡
        """
        # è·å–æˆ–åˆ›å»ºä¸Šä¸‹æ–‡
        context = self.context_manager.get_context(context_id)
        if not context:
            context_id = self.context_manager.create_context()
            context = self.context_manager.get_context(context_id)

        # æ¸…ç©ºä¸Šä¸‹æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if clear_context and context:
            context.clear_context()

        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœæä¾›ä¸”ä¸Šä¸‹æ–‡ä¸ºç©ºï¼‰
        if system_prompt and (not context.messages or all(msg["role"] != "system" for msg in context.messages)):
            context.add_message("system", system_prompt)

        # ç”Ÿæˆæ–‡æœ¬
        result = await self.generate_text(
            prompt=prompt,
            model_preference=model_preference,
            temperature=temperature,
            context_id=context_id
        )

        return {
            "result": result,
            "context_id": context_id,
            "context_info": context.get_context_info() if context else None
        }

    async def generate_image(
        self,
        prompt: str,
        model_preference: str = "doubao-seedream-4-0-250828",
        size: str = "1024x1024",
        quality: str = "standard",
        sequential_generation: str = "auto",
        max_images: int = 1,
        stream: bool = True
    ):
        """
        æ ¹æ®æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼Œæ”¯æŒç»„å›¾å’Œæµå¼è¾“å‡º

        Args:
            prompt: å›¾åƒæè¿°
            model_preference: æ¨¡å‹åå¥½
            size: å›¾åƒå°ºå¯¸
            quality: å›¾åƒè´¨é‡
            sequential_generation: ç»„å›¾è®¾ç½® ("auto" æˆ– "disabled")
            max_images: æœ€å¤§ç”Ÿæˆå›¾ç‰‡æ•°é‡ (1-5)
            stream: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º

        Returns:
            æ ¹æ®æ¨¡å¼è¿”å›ä¸åŒç»“æœï¼š
            - éæµå¼å•å›¾ï¼šè¿”å›å•ä¸ªURLå­—ç¬¦ä¸²
            - éæµå¼ç»„å›¾ï¼šè¿”å›URLåˆ—è¡¨
            - æµå¼æ¨¡å¼ï¼šè¿”å›ç”Ÿæˆå™¨å¯¹è±¡
        """
        model = "doubao-seedream-4-0-250828" if "seedream" in model_preference else self.IMAGE_MODELS[0]

        if self.provider.is_available():
            result = self.provider.text_to_image(
                model=model,
                prompt=prompt,
                size=size,
                sequential_generation=sequential_generation,
                max_images=max_images,
                stream=stream
            )

            if result is not None:
                return result

        # é™çº§å¤„ç†
        if stream:
            # æµå¼æ¨¡å¼çš„é™çº§å¤„ç† - è¿”å›åŒæ­¥ç”Ÿæˆå™¨
            def fallback_stream():
                placeholder = f"placeholder://seedream/{width}x{height}/{int(time.time())}"
                yield placeholder
            return fallback_stream()
        else:
            # éæµå¼æ¨¡å¼çš„é™çº§å¤„ç†
            if sequential_generation == "auto" and max_images > 1:
                # ç»„å›¾é™çº§ï¼šè¿”å›å¤šä¸ªå ä½ç¬¦
                placeholders = [
                    f"placeholder://seedream/{width}x{height}/{int(time.time())}_{i}"
                    for i in range(max_images)
                ]
                logger.warning(f"AIç»„å›¾æœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å› {max_images} ä¸ªå ä½ç¬¦URL")
                return placeholders
            else:
                # å•å›¾é™çº§
                placeholder = f"placeholder://seedream/{width}x{height}/{int(time.time())}"
                logger.warning(f"AIå›¾åƒæœåŠ¡ä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨å ä½ç¬¦URL: {placeholder}")
                return placeholder

    async def text_to_image(
        self,
        model: str,
        prompt: str,
        size: str = "1024x1024",
        sequential_generation: str = "auto",
        max_images: int = 1,
        stream: bool = True
    ):
        """å…¼å®¹æ‰¹å¤„ç†å™¨çš„ç­¾åï¼Œæ”¯æŒç»„å›¾å’Œæµå¼è¾“å‡ºã€‚"""
        width, height = self._parse_size(size)
        if self.provider.is_available():
            result = self.provider.text_to_image(
                model=model,
                prompt=prompt,
                width=width,
                height=height,
                sequential_generation=sequential_generation,
                max_images=max_images,
                stream=stream
            )
            if result is not None:
                return result
        return f"placeholder://{model}/{width}x{height}/{int(time.time())}"

    async def edit_image_with_base64(
        self,
        prompt: str,
        base64_image: str,
        base64_mask: Optional[str] = None,
        model_preference: str = "doubao-seedream-4-0-250828",
        size: str = "1024x1024",
        stream: bool = True,
    ) -> str:
        """ä½¿ç”¨base64å›¾åƒè¿›è¡Œç¼–è¾‘ï¼Œè¿”å›ç»“æœURLã€‚"""
        model = "doubao-seedream-4-0-250828"

        if self.provider.is_available():
            try:
                logger.info(f"å‘å›¾åƒç¼–è¾‘æ¨¡å‹ {model} å‘é€è¯·æ±‚...")
                logger.info(f"ä½¿ç”¨base64å›¾åƒè¾“å…¥ï¼Œå¤§å°: {len(base64_image)} å­—ç¬¦")

                if base64_mask:
                    logger.info(f"ä½¿ç”¨æ©ç å›¾åƒç¼–è¾‘ï¼Œæ©ç å¤§å°: {len(base64_mask)} å­—ç¬¦")
                    # TODO: å®ç°æ©ç ç¼–è¾‘é€»è¾‘
                    # ç›®å‰æš‚æ—¶ä½¿ç”¨æ— æ©ç çš„å›¾ç”Ÿå›¾
                    logger.warning("æ©ç ç¼–è¾‘åŠŸèƒ½æš‚æœªå®ç°ï¼Œä½¿ç”¨æ™®é€šå›¾ç”Ÿå›¾")

                # è°ƒç”¨å›¾ç”Ÿå›¾APIè¿›è¡Œå›¾åƒç¼–è¾‘
                result_url = self.provider.image_to_image(
                    model=model,
                    prompt=prompt,
                    image_url="",  # ç©ºURLï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨base64
                    image_base64=base64_image  # ä¼ é€’base64æ•°æ®
                )

                if result_url:
                    logger.info(f"å›¾åƒç¼–è¾‘æˆåŠŸ: {result_url}")
                    return result_url
                else:
                    logger.error("å›¾åƒç¼–è¾‘è¿”å›ç©ºç»“æœ")
                    raise Exception("å›¾åƒç¼–è¾‘è¿”å›ç©ºç»“æœ")

            except Exception as e:
                logger.error(f"å›¾åƒç¼–è¾‘å¤±è´¥: {e}")
                # é™çº§å¤„ç† - è¿”å›å ä½ç¬¦
                logger.warning("å›¾åƒç¼–è¾‘å¤±è´¥ï¼Œè¿”å›å ä½ç¬¦")
                return f"placeholder://edit-fallback-{int(time.time())}"
        else:
            # é™çº§è¿”å›å ä½ç¬¦
            logger.warning("ç«å±±å¼•æ“æœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›ç¼–è¾‘å ä½ç¬¦")
            return f"placeholder://edit-unavailable-{int(time.time())}"

    async def download_image_result(self, image_url: str, output_dir: Optional[str] = None) -> str:
        """
        ä¸‹è½½æˆ–ç”Ÿæˆå›¾åƒåˆ°æœ¬åœ°å¹¶è¿”å›è·¯å¾„ã€‚
        - http/https: ç›´æ¥ä¸‹è½½
        - placeholder://*: ç”Ÿæˆ1x1é€æ˜PNGæ–‡ä»¶
        """
        try:
            from utils.image_utils import download_image_from_url, decode_base64_to_file  # type: ignore
        except Exception:
            from utils.image_utils import download_image_from_url, decode_base64_to_file  # type: ignore

        from config import settings
        base_dir = settings.TEMP_DOWNLOADS_DIR  # æ”¹ä¸ºä½¿ç”¨downloadsç›®å½•ï¼Œæ›´æ˜ç¡®çš„ä¸´æ—¶ç”¨é€”
        target_dir = Path(output_dir) if output_dir else base_dir
        target_dir.mkdir(parents=True, exist_ok=True)

        filename = f"edit_result_{int(time.time())}_{uuid.uuid4().hex[:8]}.png"
        save_path = str(target_dir / filename)

        try:
            if image_url and image_url.startswith(("http://", "https://")):
                return await download_image_from_url(image_url, save_path)
            tiny_png_base64 = (
                "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/x8AAusB9WjhhjQAAAAASUVORK5CYII="
            )
            return decode_base64_to_file(tiny_png_base64, save_path)
        except Exception as e:
            logger.error(f"ä¸‹è½½/ç”Ÿæˆå›¾åƒå¤±è´¥: {e}")
            tiny_png_base64 = (
                "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/x8AAusB9WjhhjQAAAAASUVORK5CYII="
            )
            return decode_base64_to_file(tiny_png_base64, save_path)

    async def image_to_image_with_base64(
        self,
        prompt: str,
        base64_image: str,
        model_preference: str = "doubao-seedream-4-0-250828",
        size: str = "1024x1024",
        strength: float = 0.8,
        stream: bool = True
    ) -> str:
        """
        å›¾ç”Ÿå›¾åŠŸèƒ½ - ä½¿ç”¨base64å›¾åƒä½œä¸ºå‚è€ƒç”Ÿæˆæ–°å›¾åƒ

        Args:
            prompt: æè¿°æ–‡æœ¬
            base64_image: å‚è€ƒå›¾åƒçš„base64ç¼–ç 
            model_preference: æ¨¡å‹åå¥½
            size: å›¾åƒå°ºå¯¸
            strength: å˜åŒ–å¼ºåº¦ (0.0-1.0)ï¼Œå¯¹åº”æ¸©åº¦å‚æ•°

        Returns:
            ç”Ÿæˆå›¾åƒçš„URL
        """
        model = "doubao-seedream-4-0-250828"
        if self.provider.is_available():
            try:
                logger.info(f"å‘å›¾ç”Ÿå›¾æ¨¡å‹ {model} å‘é€è¯·æ±‚...")
                logger.info(f"ä½¿ç”¨base64å›¾åƒè¾“å…¥ï¼Œå¤§å°: {len(base64_image)} å­—ç¬¦")
                logger.info(f"å‚æ•°: size={size}, strength={strength}")

                # ç›´æ¥è°ƒç”¨provideræ–¹æ³•ï¼Œä¼ é€’æ‰€æœ‰å‚æ•°
                result_url = self.provider.image_to_image(
                    model=model,
                    prompt=prompt,
                    image_url="",  # ç©ºURLï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨base64
                    image_base64=base64_image,  # ä¼ é€’base64æ•°æ®
                    size=size,  # ä¼ é€’å°ºå¯¸å‚æ•°
                    strength=strength  # ä¼ é€’å¼ºåº¦å‚æ•°ï¼ˆæ¸©åº¦ï¼‰
                )

                if result_url:
                    logger.info(f"å›¾ç”Ÿå›¾æˆåŠŸ: {result_url}")
                    return result_url
                else:
                    logger.error("å›¾ç”Ÿå›¾è¿”å›ç©ºç»“æœ")
                    raise Exception("å›¾ç”Ÿå›¾è¿”å›ç©ºç»“æœ")

            except Exception as e:
                logger.error(f"å›¾ç”Ÿå›¾å¤±è´¥: {e}")
                # é™çº§å¤„ç† - è¿”å›å ä½ç¬¦
                logger.warning("å›¾ç”Ÿå›¾å¤±è´¥ï¼Œè¿”å›å ä½ç¬¦")
                return f"placeholder://image-to-image-fallback-{int(time.time())}"
        else:
            # é™çº§è¿”å›å ä½ç¬¦
            logger.warning("ç«å±±å¼•æ“æœåŠ¡ä¸å¯ç”¨ï¼Œè¿”å›å›¾ç”Ÿå›¾å ä½ç¬¦")
            return f"placeholder://image-to-image-unavailable-{int(time.time())}"

    async def enhance_prompt_with_reference_description(self, original_prompt: str, reference_image_path: str) -> str:
        """
        åŸºäºå‚è€ƒå›¾ç‰‡æ™ºèƒ½å¢å¼ºpromptï¼Œç¡®ä¿é£æ ¼ä¸€è‡´æ€§
        å½“å›¾ç”Ÿå›¾APIå¤±è´¥æ—¶ï¼Œé€šè¿‡æ–‡å­—æè¿°å°½é‡ä¿æŒä¸€è‡´æ€§
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹åŸºäºå‚è€ƒå›¾ç‰‡å¢å¼ºprompt: {reference_image_path}")

            # è°ƒç”¨åº•å±‚providerçš„æ–¹æ³•
            if hasattr(self.provider, 'enhance_prompt_with_reference_description'):
                enhanced_prompt = self.provider.enhance_prompt_with_reference_description(original_prompt, reference_image_path)
                logger.info(f"âœ… ä½¿ç”¨provideræ–¹æ³•å¢å¼ºpromptï¼Œé•¿åº¦: {len(enhanced_prompt)} å­—ç¬¦")
                return enhanced_prompt
            else:
                # é™çº§åˆ°é€šç”¨ä¸€è‡´æ€§æè¿°
                consistency_enhancement = """

**é‡è¦ï¼šé£æ ¼ä¸€è‡´æ€§è¦æ±‚**
åŸºäºå‚è€ƒå›¾ç‰‡ï¼Œç¡®ä¿ä»¥ä¸‹ä¸€è‡´æ€§ï¼š
1. ä¸¥æ ¼ä¿æŒç›¸åŒçš„è§’è‰²å¤–è§‚ã€å‘å‹ã€æœè£…å’Œé…é¥°
2. ä¿æŒå®Œå…¨ç›¸åŒçš„æ¼«ç”»ç»˜ç”»é£æ ¼å’Œçº¿æ¡ç‰¹å¾
3. ä¿æŒç›¸åŒçš„è‰²å½©å¤„ç†æ–¹å¼å’Œæ•´ä½“è‰²è°ƒ
4. ä¿æŒç›¸ä¼¼çš„è§’è‰²æ¯”ä¾‹å’Œèº«æç‰¹å¾
5. ä¿æŒç›¸åŒçš„èƒŒæ™¯æ¸²æŸ“é£æ ¼å’Œç»†èŠ‚å¤„ç†ç¨‹åº¦

**å¼ºåˆ¶è¦æ±‚** åŠ¡å¿…ç¡®ä¿è§’è‰²å¤–è§‚ã€æœè£…ã€å‘å‹ä¸å‚è€ƒå›¾ç‰‡å®Œå…¨ä¸€è‡´
**å¼ºåˆ¶è¦æ±‚** ä¿æŒå®Œå…¨ç›¸åŒçš„ç»˜ç”»é£æ ¼å’Œè‰²å½©å¤„ç†æ–¹å¼
"""
                enhanced_prompt = original_prompt + consistency_enhancement
                logger.info(f"âœ… ä½¿ç”¨é€šç”¨ä¸€è‡´æ€§æè¿°å¢å¼ºpromptï¼Œé•¿åº¦: {len(enhanced_prompt)} å­—ç¬¦")
                return enhanced_prompt

        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½promptå¢å¼ºå¤±è´¥: {e}")
            # æœ€åŸºç¡€çš„å¢å¼º
            return original_prompt + "ï¼Œä¿æŒä¸å‰ä¸€å¼ å›¾ç‰‡å®Œå…¨ç›¸åŒçš„è§’è‰²å¤–è§‚å’Œç»˜ç”»é£æ ¼"

