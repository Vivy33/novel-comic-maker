"""
å°é¢ç”ŸæˆæœåŠ¡
Cover Generation Service
"""

import logging
import json
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

from fastapi import UploadFile
from services.file_system import ProjectFileSystem
from services.comic_service import ComicService
from services.ai_service import AIService
from agents.cover_generator import CoverGenerator

logger = logging.getLogger(__name__)


class CoverService:
    """å°é¢ç”ŸæˆæœåŠ¡ç±»"""

    def __init__(self):
        self.ai_service = AIService()
        self.cover_generator = CoverGenerator()

    async def generate_cover(
        self,
        project_id: str,
        cover_type: str,
        novel_filename: Optional[str] = None,
        cover_prompt: str = "",
        cover_size: str = "1024x1024",
        reference_image: Optional[UploadFile] = None,
        file_system: Optional[ProjectFileSystem] = None,
        comic_service: Optional[ComicService] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ¼«ç”»å°é¢

        Args:
            project_id: é¡¹ç›®ID
            cover_type: å°é¢ç±»å‹ ("project" | "chapter")
            novel_filename: å°è¯´æ–‡ä»¶åï¼ˆç« èŠ‚å°é¢æ—¶å¿…éœ€ï¼‰
            cover_prompt: ç”¨æˆ·æä¾›çš„å°é¢æè¿°
            cover_size: å°é¢å°ºå¯¸
            reference_image: å‚è€ƒå›¾ç‰‡æ–‡ä»¶
            file_system: æ–‡ä»¶ç³»ç»ŸæœåŠ¡
            comic_service: æ¼«ç”»æœåŠ¡

        Returns:
            å°é¢ç”Ÿæˆç»“æœ
        """
        try:
            logger.info(f"å¼€å§‹ç”Ÿæˆå°é¢ - é¡¹ç›®: {project_id}, ç±»å‹: {cover_type}")
            # è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°æ‰€æœ‰è¾“å…¥å‚æ•°
            logger.info(f"ğŸ” è°ƒè¯•ï¼šæ”¶åˆ°å°é¢ç”Ÿæˆè¯·æ±‚")
            logger.info(f"ğŸ” è°ƒè¯•ï¼šcover_type = {cover_type}")
            logger.info(f"ğŸ” è°ƒè¯•ï¼šnovel_filename = {novel_filename}")
            logger.info(f"ğŸ” è°ƒè¯•ï¼šcover_prompt = '{cover_prompt}' (é•¿åº¦: {len(cover_prompt)})")
            logger.info(f"ğŸ” è°ƒè¯•ï¼šcover_size = {cover_size}")
            logger.info(f"ğŸ” è°ƒè¯•ï¼šreference_image = {reference_image}")

            # è·å–é¡¹ç›®è·¯å¾„
            if not file_system:
                file_system = ProjectFileSystem()

            project_path_str = file_system.get_project_path(project_id)
            if not project_path_str:
                raise ValueError(f"é¡¹ç›® {project_id} ä¸å­˜åœ¨")
            project_path = Path(project_path_str)

            # å¤„ç†å‚è€ƒå›¾
            reference_image_path = None
            if reference_image and reference_image.filename:
                reference_image_path = await self._save_reference_image(
                    project_path, reference_image
                )

            # ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„å°é¢æè¿°ï¼Œä¸è¿›è¡ŒAIåˆ†æ
            cover_description = cover_prompt.strip() if cover_prompt.strip() else f"ç²¾ç¾çš„æ¼«ç”»{cover_type}å°é¢"

            # ç”Ÿæˆå°é¢å›¾åƒ
            image_result = await self._generate_cover_image(
                description=cover_description,
                size=cover_size,
                reference_image_path=reference_image_path
            )

            # ä¸‹è½½å›¾ç‰‡åˆ°æœ¬åœ°
            local_image_path = None
            logger.info(f"å¼€å§‹ä¸‹è½½å›¾ç‰‡ï¼Œimage_result: {image_result}")
            if image_result.get("image_url"):
                logger.info(f"å›¾ç‰‡URLå­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½: {image_result['image_url']}")
                try:
                    # æ ¹æ®å°é¢ç±»å‹åˆ›å»ºå¯¹åº”ç›®å½•
                    if cover_type == "project":
                        covers_dir = project_path / "covers" / "project"
                    else:
                        covers_dir = project_path / "covers" / "chapters"

                    covers_dir.mkdir(parents=True, exist_ok=True)
                    logger.info(f"å°é¢ç›®å½•å·²åˆ›å»º: {covers_dir}")

                    # ä¸‹è½½å›¾ç‰‡åˆ°å¯¹åº”ç±»å‹ç›®å½•
                    local_image_path = await self.ai_service.download_image_result(
                        image_result["image_url"],
                        str(covers_dir)
                    )
                    logger.info(f"å›¾ç‰‡å·²ä¸‹è½½åˆ°æœ¬åœ°: {local_image_path}")
                except Exception as e:
                    logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
                    import traceback
                    logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                    # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨è¿œç¨‹URL
            else:
                logger.warning("image_resultä¸­æ²¡æœ‰image_urlå­—æ®µ")

            # ä¿å­˜å°é¢ä¿¡æ¯
            cover_data = {
                "cover_id": f"cover_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "project_id": project_id,
                "cover_type": cover_type,
                "related_novel": novel_filename,
                "title": self._generate_cover_title(cover_type, novel_filename, project_path),
                "description": cover_description,
                "size": cover_size,
                "reference_image_path": reference_image_path,
                "image_url": image_result.get("image_url"),
                "local_path": local_image_path,
                "status": "completed",
                "created_at": datetime.now().isoformat()
            }

            # ä¿å­˜åˆ°æ–‡ä»¶ç³»ç»Ÿ
            await self._save_cover_data(project_path, cover_data)

            logger.info(f"å°é¢ç”Ÿæˆå®Œæˆ: {cover_data['cover_id']}")

            return {
                "success": True,
                "cover_id": cover_data["cover_id"],
                "title": cover_data["title"],
                "description": cover_data["description"],
                "image_url": cover_data["image_url"],
                "local_path": cover_data["local_path"],
                "cover_type": cover_data["cover_type"],
                "related_novel": cover_data["related_novel"],
                "status": cover_data["status"]
            }

        except Exception as e:
            logger.error(f"å°é¢ç”Ÿæˆå¤±è´¥: {e}")
            raise

  
    async def _generate_cover_image(
        self,
        description: str,
        size: str,
        reference_image_path: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå°é¢å›¾åƒ - ç›´æ¥ä½¿ç”¨seedreamï¼Œä¸è¿›è¡Œä»»ä½•AIåˆ†æ
        """
        try:
            # å®Œå…¨ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„æè¿°ï¼Œä¸æ·»åŠ ä»»ä½•ä¿®é¥°è¯
            final_prompt = description

            logger.info(f"ğŸ¨ å¼€å§‹ç”Ÿæˆå›¾åƒï¼Œå°ºå¯¸: {size}")
            logger.info(f"ğŸ“ æœ€ç»ˆprompt: {final_prompt}")

            if reference_image_path:
                # ä½¿ç”¨å‚è€ƒå›¾ç‰‡è¿›è¡Œå›¾ç”Ÿå›¾
                logger.info(f"ğŸ“¸ ä½¿ç”¨å‚è€ƒå›¾ç‰‡è¿›è¡Œå›¾ç”Ÿå›¾: {reference_image_path}")

                # è¯»å–å‚è€ƒå›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
                import base64
                try:
                    with open(reference_image_path, 'rb') as f:
                        image_data = f.read()
                    image_base64 = base64.b64encode(image_data).decode('utf-8')
                    logger.info(f"âœ… å‚è€ƒå›¾ç‰‡å·²è½¬æ¢ä¸ºbase64ï¼Œå¤§å°: {len(image_base64)} å­—ç¬¦")
                except Exception as e:
                    logger.error(f"è¯»å–å‚è€ƒå›¾ç‰‡å¤±è´¥: {e}")
                    image_base64 = None

                if image_base64:
                    # ç›´æ¥è°ƒç”¨åº•å±‚providerçš„å›¾ç”Ÿå›¾APIï¼Œä¸è¿›è¡Œä»»ä½•AIåˆ†æ
                    logger.info(f"ğŸ”„ è°ƒç”¨seedreamå›¾ç”Ÿå›¾APIï¼Œprompté•¿åº¦: {len(final_prompt)}, å›¾ç‰‡å¤§å°: {len(image_base64)}")
                    result = self.ai_service.provider.image_to_image(
                        model="doubao-seedream-4-0-250828",
                        prompt=final_prompt,
                        image_url="",  # ç©ºURLï¼Œä½¿ç”¨base64
                        image_base64=image_base64
                    )
                    logger.info(f"ğŸ”„ seedreamå›¾ç”Ÿå›¾APIè¿”å›: {type(result)} - {result}")

                    # å¦‚æœimage_to_imageå¤±è´¥ï¼Œé™çº§åˆ°æ™®é€šæ–‡ç”Ÿå›¾ä½†ä¸æ·»åŠ AIåˆ†æ
                    if result is None:
                        logger.warning("å›¾ç”Ÿå›¾APIå¤±è´¥ï¼Œé™çº§åˆ°æ–‡ç”Ÿå›¾ï¼ˆä¸è¿›è¡ŒAIåˆ†æï¼‰")
                        result = self.ai_service.provider.text_to_image(
                            model="doubao-seedream-4-0-250828",
                            prompt=final_prompt,
                            size=size,
                            sequential_generation="auto",
                            max_images=1,
                            stream=False
                        )
                else:
                    # å‚è€ƒå›¾ç‰‡è¯»å–å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šæ–‡ç”Ÿå›¾
                    logger.warning("å‚è€ƒå›¾ç‰‡è¯»å–å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šæ–‡ç”Ÿå›¾")
                    result = self.ai_service.provider.text_to_image(
                        model="doubao-seedream-4-0-250828",
                        prompt=final_prompt,
                        size=size,
                        sequential_generation="auto",
                        max_images=1,
                        stream=False
                    )
            else:
                # çº¯æ–‡æœ¬ç”Ÿå›¾ï¼Œä¸è¿›è¡Œä»»ä½•AIåˆ†æ
                logger.info(f"â„¹ï¸ æœªæä¾›å‚è€ƒå›¾ç‰‡ï¼Œä½¿ç”¨çº¯æ–‡æœ¬ç”Ÿå›¾")
                result = self.ai_service.provider.text_to_image(
                    model="doubao-seedream-4-0-250828",
                    prompt=final_prompt,
                    size=size,
                    sequential_generation="auto",
                    max_images=1,
                    stream=False
                )

            if result is None:
                raise Exception("seedreamå›¾åƒç”Ÿæˆè¿”å›ç©ºç»“æœ")

            # å¤„ç†ä¸åŒç±»å‹çš„è¿”å›ç»“æœ
            image_url = None
            if isinstance(result, str):
                image_url = result
            elif isinstance(result, dict):
                # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸ï¼Œå°è¯•è·å–å¸¸è§çš„URLå­—æ®µ
                image_url = result.get("image_url") or result.get("url") or result.get("image")
            else:
                logger.error(f"âŒ seedreamè¿”å›äº†æ„å¤–çš„ç»“æœç±»å‹: {type(result)}, å†…å®¹: {result}")
                raise Exception(f"seedreamè¿”å›äº†æ„å¤–çš„ç»“æœç±»å‹: {type(result)}")

            if not image_url:
                raise Exception("æ— æ³•ä»seedreamç»“æœä¸­æå–å›¾åƒURL")

            logger.info(f"âœ… seedreamå›¾åƒç”ŸæˆæˆåŠŸï¼ŒURL: {image_url}")
            return {"image_url": image_url}

        except Exception as e:
            logger.error(f"ç”Ÿæˆå°é¢å›¾åƒå¤±è´¥: {e}")
            raise

    def _generate_cover_title(
        self,
        cover_type: str,
        novel_filename: Optional[str],
        project_path: Path
    ) -> str:
        """
        ç”Ÿæˆå°é¢æ ‡é¢˜
        """
        try:
            if cover_type == "project":
                # é¡¹ç›®å°é¢
                meta_file = project_path / "meta" / "project.json"
                if meta_file.exists():
                    with open(meta_file, 'r', encoding='utf-8') as f:
                        project_info = json.load(f)
                        return f"{project_info.get('name', 'é¡¹ç›®')}å°é¢"
                return "é¡¹ç›®å°é¢"
            else:
                # ç« èŠ‚å°é¢
                if novel_filename:
                    # ä»å°è¯´æ–‡ä»¶åç”Ÿæˆæ ‡é¢˜
                    title = Path(novel_filename).stem
                    return f"{title}å°é¢"
                return "ç« èŠ‚å°é¢"

        except Exception as e:
            logger.error(f"ç”Ÿæˆå°é¢æ ‡é¢˜å¤±è´¥: {e}")
            return "æ¼«ç”»å°é¢"

    async def _save_cover_data(self, project_path: Path, cover_data: Dict[str, Any]):
        """
        ä¿å­˜å°é¢æ•°æ®åˆ°æ–‡ä»¶ç³»ç»Ÿï¼Œæ”¯æŒåˆ†å±‚ç›®å½•ç»“æ„
        """
        try:
            # åˆ›å»ºåˆ†å±‚å°é¢ç›®å½•ç»“æ„
            if cover_data["cover_type"] == "project":
                # é¡¹ç›®å°é¢å­˜å‚¨åœ¨ project/covers/ ç›®å½•
                cover_type_dir = project_path / "covers" / "project"
            else:
                # ç« èŠ‚å°é¢å­˜å‚¨åœ¨ chapters/covers/ ç›®å½•
                cover_type_dir = project_path / "covers" / "chapters"

            cover_type_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜å°é¢æ•°æ®åˆ°å¯¹åº”ç±»å‹ç›®å½•
            cover_file = cover_type_dir / f"{cover_data['cover_id']}.json"
            with open(cover_file, 'w', encoding='utf-8') as f:
                json.dump(cover_data, f, ensure_ascii=False, indent=2)

            # æ›´æ–°é¡¹ç›®å°é¢åˆ—è¡¨ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            covers_list_file = project_path / "covers" / "covers_list.json"
            covers_list = []

            if covers_list_file.exists():
                with open(covers_list_file, 'r', encoding='utf-8') as f:
                    covers_list = json.load(f)

            covers_list.append({
                "cover_id": cover_data["cover_id"],
                "title": cover_data["title"],
                "cover_type": cover_data["cover_type"],
                "related_novel": cover_data["related_novel"],
                "created_at": cover_data["created_at"],
                "image_url": cover_data["image_url"],
                "local_path": cover_data["local_path"]
            })

            with open(covers_list_file, 'w', encoding='utf-8') as f:
                json.dump(covers_list, f, ensure_ascii=False, indent=2)

            # åŒæ—¶åœ¨å¯¹åº”ç±»å‹ç›®å½•ä¸‹ç»´æŠ¤ç±»å‹ä¸“å±åˆ—è¡¨
            if cover_data["cover_type"] == "project":
                project_list_file = project_path / "covers" / "project" / "covers_list.json"
            else:
                project_list_file = project_path / "covers" / "chapters" / "covers_list.json"

            type_covers_list = []
            if project_list_file.exists():
                with open(project_list_file, 'r', encoding='utf-8') as f:
                    type_covers_list = json.load(f)

            type_covers_list.append({
                "cover_id": cover_data["cover_id"],
                "title": cover_data["title"],
                "cover_type": cover_data["cover_type"],
                "related_novel": cover_data["related_novel"],
                "created_at": cover_data["created_at"],
                "image_url": cover_data["image_url"],
                "local_path": cover_data["local_path"]
            })

            with open(project_list_file, 'w', encoding='utf-8') as f:
                json.dump(type_covers_list, f, ensure_ascii=False, indent=2)

            logger.info(f"å°é¢æ•°æ®å·²ä¿å­˜: {cover_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜å°é¢æ•°æ®å¤±è´¥: {e}")
            raise

    async def _save_reference_image(self, project_path: Path, reference_image: UploadFile) -> str:
        """
        ä¿å­˜å‚è€ƒå›¾ç‰‡åˆ°é¡¹ç›®ç›®å½•ï¼Œä½¿ç”¨ä¸“é—¨çš„å‚è€ƒå›¾ç‰‡ç›®å½•
        """
        try:
            logger.info(f"ğŸ” åç«¯è°ƒè¯•ï¼šå¼€å§‹ä¿å­˜å‚è€ƒå›¾ç‰‡")
            logger.info(f"ğŸ” åç«¯è°ƒè¯•ï¼šreference_image.filename = {reference_image.filename}")
            logger.info(f"ğŸ” åç«¯è°ƒè¯•ï¼šreference_image.content_type = {reference_image.content_type}")
            logger.info(f"ğŸ” åç«¯è°ƒè¯•ï¼šreference_image.size = {reference_image.size}")
            logger.info(f"ğŸ” åç«¯è°ƒè¯•ï¼šproject_path = {project_path}")

            # åˆ›å»ºä¸“é—¨çš„å‚è€ƒå›¾ç›®å½•
            ref_images_dir = project_path / "covers" / "reference_images"
            ref_images_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"âœ… åç«¯è°ƒè¯•ï¼šå‚è€ƒå›¾ç‰‡ç›®å½•å·²åˆ›å»º: {ref_images_dir}")

            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_extension = Path(reference_image.filename).suffix or ".jpg"
            # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
            safe_filename = "".join(c for c in Path(reference_image.filename).stem if c.isalnum() or c in (' ', '-', '_')).rstrip()
            if not safe_filename:
                safe_filename = "reference"
            filename = f"ref_{timestamp}_{safe_filename}{file_extension}"
            file_path = ref_images_dir / filename
            logger.info(f"âœ… åç«¯è°ƒè¯•ï¼šç”Ÿæˆæ–‡ä»¶å: {filename}")
            logger.info(f"âœ… åç«¯è°ƒè¯•ï¼šå®Œæ•´æ–‡ä»¶è·¯å¾„: {file_path}")

            # ä¿å­˜æ–‡ä»¶å†…å®¹
            logger.info(f"ğŸ”„ åç«¯è°ƒè¯•ï¼šå¼€å§‹è¯»å–æ–‡ä»¶å†…å®¹")
            file_content = await reference_image.read()
            logger.info(f"âœ… åç«¯è°ƒè¯•ï¼šæ–‡ä»¶å†…å®¹è¯»å–å®Œæˆï¼Œå¤§å°: {len(file_content)} bytes")

            logger.info(f"ğŸ’¾ åç«¯è°ƒè¯•ï¼šå¼€å§‹å†™å…¥æ–‡ä»¶åˆ°ç£ç›˜")
            with open(file_path, "wb") as buffer:
                buffer.write(file_content)

            # éªŒè¯æ–‡ä»¶æ˜¯å¦æˆåŠŸå†™å…¥
            if file_path.exists():
                actual_size = file_path.stat().st_size
                logger.info(f"âœ… åç«¯è°ƒè¯•ï¼šæ–‡ä»¶å†™å…¥æˆåŠŸï¼Œå®é™…å¤§å°: {actual_size} bytes")
            else:
                logger.error(f"âŒ åç«¯è°ƒè¯•ï¼šæ–‡ä»¶å†™å…¥å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")
                raise Exception("æ–‡ä»¶å†™å…¥å¤±è´¥")

            logger.info(f"âœ… å‚è€ƒå›¾å·²ä¿å­˜: {file_path} (å¤§å°: {len(file_content)} bytes)")
            # è¿”å›ç»å¯¹è·¯å¾„ï¼Œé¿å…åç»­è¯»å–æ—¶æ‰¾ä¸åˆ°æ–‡ä»¶
            return str(file_path)

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å‚è€ƒå›¾å¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            raise

    def get_project_covers(self, project_id: str, file_system: ProjectFileSystem) -> List[Dict[str, Any]]:
        """
        è·å–é¡¹ç›®å°é¢åˆ—è¡¨ï¼Œæ”¯æŒæ–°çš„åˆ†å±‚ç›®å½•ç»“æ„ï¼ŒåŒæ—¶ä¿æŒå‘åå…¼å®¹
        è‡ªåŠ¨æ¸…ç†æŒ‡å‘ä¸å­˜åœ¨æ–‡ä»¶çš„å°é¢è®°å½•
        """
        try:
            project_path_str = file_system.get_project_path(project_id)
            if not project_path_str:
                raise ValueError(f"é¡¹ç›® {project_id} ä¸å­˜åœ¨")
            project_path = Path(project_path_str)

            covers_list = []
            processed_cover_ids = set()

            # 1. ä¼˜å…ˆè¯»å–æ ¹ç›®å½•çš„ covers_list.json (å…¼å®¹æ—§ç»“æ„)
            covers_list_file = project_path / "covers" / "covers_list.json"
            if covers_list_file.exists():
                logger.info(f"å‘ç°æ—§ç‰ˆå°é¢åˆ—è¡¨æ–‡ä»¶: {covers_list_file}")
                with open(covers_list_file, 'r', encoding='utf-8') as f:
                    try:
                        old_covers = json.load(f)
                        if isinstance(old_covers, list):
                            covers_list.extend(old_covers)
                            processed_cover_ids.update(c.get("cover_id") for c in old_covers)
                            logger.info(f"ä»æ—§ç‰ˆåˆ—è¡¨åŠ è½½äº† {len(old_covers)} ä¸ªå°é¢")
                    except json.JSONDecodeError:
                        logger.warning(f"æ— æ³•è§£ææ—§ç‰ˆå°é¢åˆ—è¡¨: {covers_list_file}")

            # 2. æ‰«æå­ç›®å½•ä¸­çš„ .json æ–‡ä»¶ (æ–°ç»“æ„)
            subdirs_to_scan = [
                project_path / "covers" / "project",
                project_path / "covers" / "chapters"
            ]
            for subdir in subdirs_to_scan:
                if subdir.exists():
                    logger.info(f"æ‰«ææ–°ç‰ˆå°é¢ç›®å½•: {subdir}")
                    for json_file in subdir.glob("*.json"):
                        if json_file.name == "covers_list.json":
                            continue
                        try:
                            with open(json_file, 'r', encoding='utf-8') as f:
                                cover_data = json.load(f)
                                if isinstance(cover_data, dict) and "cover_id" in cover_data:
                                    if cover_data["cover_id"] not in processed_cover_ids:
                                        covers_list.append(cover_data)
                                        processed_cover_ids.add(cover_data["cover_id"])
                                        logger.info(f"ä» {json_file.name} åŠ è½½äº†æ–°å°é¢: {cover_data['cover_id']}")
                        except (json.JSONDecodeError, KeyError) as e:
                            logger.warning(f"æ— æ³•å¤„ç†å°é¢JSONæ–‡ä»¶ {json_file}: {e}")
            
            logger.info(f"å…±åŠ è½½äº† {len(covers_list)} ä¸ªå°é¢è®°å½•")

            # æ¸…ç†æ— æ•ˆçš„å°é¢è®°å½•
            cleaned_covers = self._clean_invalid_covers(covers_list, project_path)

            # å¦‚æœæœ‰æ¸…ç†æ“ä½œï¼Œä¿å­˜æ¸…ç†åçš„æ•°æ®
            if len(cleaned_covers) != len(covers_list):
                logger.info(f"æ¸…ç†äº† {len(covers_list) - len(cleaned_covers)} æ¡æ— æ•ˆå°é¢è®°å½•")
                self._save_cleaned_covers(project_path, cleaned_covers)

            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            cleaned_covers.sort(key=lambda x: x.get("created_at", ""), reverse=True)

            return cleaned_covers

        except Exception as e:
            logger.error(f"è·å–å°é¢åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _clean_invalid_covers(self, covers_list: List[Dict[str, Any]], project_path: Path) -> List[Dict[str, Any]]:
        """
        æ¸…ç†æŒ‡å‘ä¸å­˜åœ¨æ–‡ä»¶çš„å°é¢è®°å½•
        """
        try:
            valid_covers = []
            invalid_count = 0

            # è·å–æ‰€æœ‰å®é™…å­˜åœ¨çš„PNGæ–‡ä»¶
            actual_files = set()
            for png_file in project_path.rglob('*.png'):
                if 'covers' in str(png_file):
                    actual_files.add(png_file.name)

            for cover in covers_list:
                local_path = cover.get('local_path', '')

                if not local_path:
                    # æ²¡æœ‰æœ¬åœ°è·¯å¾„ä½†æœ‰è¿œç¨‹URLçš„è®°å½•ä¿ç•™
                    if cover.get('image_url'):
                        valid_covers.append(cover)
                    else:
                        logger.warning(f"å°é¢è®°å½•ç¼ºå°‘æ–‡ä»¶è·¯å¾„å’ŒURL: {cover.get('cover_id', 'unknown')}")
                        invalid_count += 1
                    continue

                # æå–æ–‡ä»¶å
                filename = Path(local_path).name

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if filename in actual_files:
                    valid_covers.append(cover)
                else:
                    logger.warning(f"å°é¢æ–‡ä»¶ä¸å­˜åœ¨: {cover.get('cover_id', 'unknown')} -> {filename}")
                    invalid_count += 1

            if invalid_count > 0:
                logger.info(f"å‘ç° {invalid_count} æ¡æ— æ•ˆå°é¢è®°å½•ï¼Œå·²æ¸…ç†")

            return valid_covers

        except Exception as e:
            logger.error(f"æ¸…ç†æ— æ•ˆå°é¢è®°å½•å¤±è´¥: {e}")
            # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹åˆ—è¡¨
            return covers_list

    def _save_cleaned_covers(self, project_path: Path, cleaned_covers: List[Dict[str, Any]]):
        """
        ä¿å­˜æ¸…ç†åçš„å°é¢æ•°æ®
        """
        try:
            # æ›´æ–°ä¸»è¦çš„covers_list.jsonæ–‡ä»¶
            covers_list_file = project_path / "covers" / "covers_list.json"

            with open(covers_list_file, 'w', encoding='utf-8') as f:
                json.dump(cleaned_covers, f, ensure_ascii=False, indent=2)

            logger.info(f"å·²ä¿å­˜æ¸…ç†åçš„å°é¢åˆ—è¡¨åˆ°: {covers_list_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜æ¸…ç†åçš„å°é¢æ•°æ®å¤±è´¥: {e}")

    async def get_cover_details(
        self,
        project_id: str,
        cover_id: str,
        file_system: ProjectFileSystem
    ) -> Optional[Dict[str, Any]]:
        """
        è·å–å°é¢è¯¦ç»†ä¿¡æ¯ï¼Œæ”¯æŒæ–°çš„åˆ†å±‚ç›®å½•ç»“æ„ï¼ŒåŒæ—¶ä¿æŒå‘åå…¼å®¹
        """
        try:
            project_path_str = file_system.get_project_path(project_id)
            if not project_path_str:
                return None
            project_path = Path(project_path_str)

            # é¦–å…ˆå°è¯•ä»ä¼ ç»Ÿç›®å½•æŸ¥æ‰¾ï¼ˆå‘åå…¼å®¹ï¼‰
            cover_file = project_path / "covers" / f"{cover_id}.json"
            if cover_file.exists():
                with open(cover_file, 'r', encoding='utf-8') as f:
                    return json.load(f)

            # å¦‚æœä¼ ç»Ÿç›®å½•ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»æ–°çš„åˆ†å±‚ç›®å½•æŸ¥æ‰¾
            # åœ¨é¡¹ç›®å°é¢ç›®å½•ä¸­æŸ¥æ‰¾
            project_cover_file = project_path / "covers" / "project" / f"{cover_id}.json"
            if project_cover_file.exists():
                with open(project_cover_file, 'r', encoding='utf-8') as f:
                    return json.load(f)

            # åœ¨ç« èŠ‚å°é¢ç›®å½•ä¸­æŸ¥æ‰¾
            chapter_cover_file = project_path / "covers" / "chapters" / f"{cover_id}.json"
            if chapter_cover_file.exists():
                with open(chapter_cover_file, 'r', encoding='utf-8') as f:
                    return json.load(f)

            return None

        except Exception as e:
            logger.error(f"è·å–å°é¢è¯¦æƒ…å¤±è´¥: {e}")
            return None

    def delete_cover(
        self,
        project_id: str,
        cover_id: str,
        file_system: ProjectFileSystem
    ) -> bool:
        """
        åˆ é™¤å°é¢ï¼Œæ”¯æŒæ–°çš„åˆ†å±‚ç›®å½•ç»“æ„ï¼ŒåŒæ—¶ä¿æŒå‘åå…¼å®¹
        """
        try:
            project_path_str = file_system.get_project_path(project_id)
            if not project_path_str:
                raise FileNotFoundError(f"é¡¹ç›® {project_id} ä¸å­˜åœ¨")
            project_path = Path(project_path_str)

            cover_deleted = False
            cover_data = None

            # é¦–å…ˆå°è¯•ä»ä¼ ç»Ÿç›®å½•æŸ¥æ‰¾å¹¶åˆ é™¤ï¼ˆå‘åå…¼å®¹ï¼‰
            cover_file = project_path / "covers" / f"{cover_id}.json"
            if cover_file.exists():
                with open(cover_file, 'r', encoding='utf-8') as f:
                    cover_data = json.load(f)
                cover_file.unlink()
                cover_deleted = True
                logger.info(f"ä»ä¼ ç»Ÿç›®å½•åˆ é™¤å°é¢æ–‡ä»¶: {cover_file}")

            # å¦‚æœä¼ ç»Ÿç›®å½•ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»æ–°çš„åˆ†å±‚ç›®å½•æŸ¥æ‰¾å¹¶åˆ é™¤
            if not cover_deleted:
                # åœ¨é¡¹ç›®å°é¢ç›®å½•ä¸­æŸ¥æ‰¾
                project_cover_file = project_path / "covers" / "project" / f"{cover_id}.json"
                if project_cover_file.exists():
                    with open(project_cover_file, 'r', encoding='utf-8') as f:
                        cover_data = json.load(f)
                    project_cover_file.unlink()
                    cover_deleted = True
                    logger.info(f"ä»é¡¹ç›®å°é¢ç›®å½•åˆ é™¤å°é¢æ–‡ä»¶: {project_cover_file}")

                # åœ¨ç« èŠ‚å°é¢ç›®å½•ä¸­æŸ¥æ‰¾
                if not cover_deleted:
                    chapter_cover_file = project_path / "covers" / "chapters" / f"{cover_id}.json"
                    if chapter_cover_file.exists():
                        with open(chapter_cover_file, 'r', encoding='utf-8') as f:
                            cover_data = json.load(f)
                        chapter_cover_file.unlink()
                        cover_deleted = True
                        logger.info(f"ä»ç« èŠ‚å°é¢ç›®å½•åˆ é™¤å°é¢æ–‡ä»¶: {chapter_cover_file}")

            if not cover_deleted:
                logger.warning(f"å°é¢ {cover_id} çš„æ–‡ä»¶æœªæ‰¾åˆ°")
            else:
                # åˆ é™¤æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                covers_dir = project_path / "covers"
                for img_file in covers_dir.rglob(f"{cover_id}*"):
                    if img_file.is_file() and img_file.name.startswith(cover_id):
                        img_file.unlink()
                        logger.info(f"åˆ é™¤å›¾ç‰‡æ–‡ä»¶: {img_file}")

                # æ›´æ–°æ‰€æœ‰ç›¸å…³çš„å°é¢åˆ—è¡¨æ–‡ä»¶
                list_files_to_update = [
                    project_path / "covers" / "covers_list.json",
                    project_path / "covers" / "project" / "covers_list.json",
                    project_path / "covers" / "chapters" / "covers_list.json"
                ]

                for list_file in list_files_to_update:
                    if list_file.exists():
                        with open(list_file, 'r', encoding='utf-8') as f:
                            covers_list = json.load(f)

                        # ç§»é™¤æŒ‡å®šçš„å°é¢
                        original_length = len(covers_list)
                        covers_list = [cover for cover in covers_list if cover.get("cover_id") != cover_id]

                        # å¦‚æœæœ‰åˆ é™¤ï¼Œä¿å­˜æ›´æ–°åçš„åˆ—è¡¨
                        if len(covers_list) != original_length:
                            with open(list_file, 'w', encoding='utf-8') as f:
                                json.dump(covers_list, f, ensure_ascii=False, indent=2)
                            logger.info(f"æ›´æ–°å°é¢åˆ—è¡¨æ–‡ä»¶: {list_file}")

            logger.info(f"å°é¢ {cover_id} åˆ é™¤æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"åˆ é™¤å°é¢å¤±è´¥: {e}")
            raise

    def set_primary_cover(
        self,
        project_id: str,
        cover_id: str,
        file_system: ProjectFileSystem
    ) -> Dict[str, Any]:
        """
        è®¾ç½®ä¸»è¦å°é¢ï¼Œæ”¯æŒæ–°çš„åˆ†å±‚ç›®å½•ç»“æ„ï¼ŒåŒæ—¶ä¿æŒå‘åå…¼å®¹
        """
        try:
            project_path_str = file_system.get_project_path(project_id)
            if not project_path_str:
                raise FileNotFoundError(f"é¡¹ç›® {project_id} ä¸å­˜åœ¨")
            project_path = Path(project_path_str)

            # éœ€è¦æ›´æ–°çš„æ‰€æœ‰å°é¢åˆ—è¡¨æ–‡ä»¶
            list_files_to_update = [
                project_path / "covers" / "covers_list.json",
                project_path / "covers" / "project" / "covers_list.json",
                project_path / "covers" / "chapters" / "covers_list.json"
            ]

            target_cover = None

            # éå†æ‰€æœ‰åˆ—è¡¨æ–‡ä»¶ï¼Œæ‰¾åˆ°å¹¶æ›´æ–°ç›®æ ‡å°é¢
            for list_file in list_files_to_update:
                if list_file.exists():
                    with open(list_file, 'r', encoding='utf-8') as f:
                        covers_list = json.load(f)

                    # æŸ¥æ‰¾ç›®æ ‡å°é¢å¹¶æ›´æ–°ä¸»å°é¢çŠ¶æ€
                    updated_covers = []
                    for cover in covers_list:
                        if cover.get("cover_id") == cover_id:
                            target_cover = cover.copy()
                            # è®¾ç½®ä¸ºä¸»è¦å°é¢
                            target_cover["is_primary"] = True
                            updated_covers.append(target_cover)
                        else:
                            # ç§»é™¤å…¶ä»–å°é¢çš„ä¸»å°é¢æ ‡è®°
                            cover_copy = cover.copy()
                            cover_copy.pop("is_primary", None)
                            updated_covers.append(cover_copy)

                    # ä¿å­˜æ›´æ–°åçš„åˆ—è¡¨
                    with open(list_file, 'w', encoding='utf-8') as f:
                        json.dump(updated_covers, f, ensure_ascii=False, indent=2)

                    logger.info(f"æ›´æ–°å°é¢åˆ—è¡¨æ–‡ä»¶: {list_file}")

            if not target_cover:
                raise ValueError(f"å°é¢ {cover_id} ä¸å­˜åœ¨")

            logger.info(f"å°é¢ {cover_id} å·²è®¾ç½®ä¸ºä¸»è¦å°é¢")
            return target_cover

        except Exception as e:
            logger.error(f"è®¾ç½®ä¸»è¦å°é¢å¤±è´¥: {e}")
            raise